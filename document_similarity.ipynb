{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity using LDA and gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context-based similar documents problem can help us to find the similar documents of document which are necceesary. Many times, people do recommend the several items, which could be related to several data that customers read. Several techniques are there to find the similarity between the document but, in this project we will be using the concept of LDA and gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import codecs\n",
    "from gensim import models, similarities\n",
    "import os\n",
    "import pickle\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "colnames=[\"id\",\"title\",\"content\"]\n",
    "inf = pandas.read_csv('articles1.csv',columns=colnames, nrows=10)\n",
    "#data= inf.content.tolist()\n",
    "#fileid=inf.id.tolist()\n",
    "#name=inf.title.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the Structure of Dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains 5000 entries and 10 columns. Following is the glimpse of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <td>month</td>\n",
       "      <td>url</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <th>17283</th>\n",
       "      <th>House Republicans Fret About Winning Their Health Care Suit - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>Carl Hulse</th>\n",
       "      <th>2016-12-31</th>\n",
       "      <th>2016.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>17284</th>\n",
       "      <th>Rift Between Officers and Residents as Killings Persist in South Bronx - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>Benjamin Mueller and Al Baker</th>\n",
       "      <th>2017-06-19</th>\n",
       "      <th>2017.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>17285</th>\n",
       "      <th>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial Bias, Dies at 106 - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>Margalit Fox</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>17286</th>\n",
       "      <th>Among Deaths in 2016, a Heavy Toll in Pop Music - The New York Times</th>\n",
       "      <th>New York Times</th>\n",
       "      <th>William McDonald</th>\n",
       "      <th>2017-04-10</th>\n",
       "      <th>2017.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                id  \\\n",
       "NaN id    title                                              publication    author                        date       year    month   \n",
       "0.0 17283 House Republicans Fret About Winning Their Heal... New York Times Carl Hulse                    2016-12-31 2016.0   12.0   \n",
       "1.0 17284 Rift Between Officers and Residents as Killings... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017.0    6.0   \n",
       "2.0 17285 Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial B... New York Times Margalit Fox                  2017-01-06 2017.0    1.0   \n",
       "3.0 17286 Among Deaths in 2016, a Heavy Toll in Pop Music... New York Times William McDonald              2017-04-10 2017.0    4.0   \n",
       "\n",
       "                                                                                                                            title  \\\n",
       "NaN id    title                                              publication    author                        date       year     url   \n",
       "0.0 17283 House Republicans Fret About Winning Their Heal... New York Times Carl Hulse                    2016-12-31 2016.0   NaN   \n",
       "1.0 17284 Rift Between Officers and Residents as Killings... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017.0   NaN   \n",
       "2.0 17285 Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial B... New York Times Margalit Fox                  2017-01-06 2017.0   NaN   \n",
       "3.0 17286 Among Deaths in 2016, a Heavy Toll in Pop Music... New York Times William McDonald              2017-04-10 2017.0   NaN   \n",
       "\n",
       "                                                                                                                                                                       content  \n",
       "NaN id    title                                              publication    author                        date       year                                              content  \n",
       "0.0 17283 House Republicans Fret About Winning Their Heal... New York Times Carl Hulse                    2016-12-31 2016.0  WASHINGTON  —   Congressional Republicans have...  \n",
       "1.0 17284 Rift Between Officers and Residents as Killings... New York Times Benjamin Mueller and Al Baker 2017-06-19 2017.0  After the bullet shells get counted, the blood...  \n",
       "2.0 17285 Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial B... New York Times Margalit Fox                  2017-01-06 2017.0  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3.0 17286 Among Deaths in 2016, a Heavy Toll in Pop Music... New York Times William McDonald              2017-04-10 2017.0  Death may be the great equalizer, but it isn’t...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is/are some useful features in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our basic aim is to find any similar documents to our query. so for here in our dataset, there are four main coloumns, which are really neccessary for us to build our project. Four main coloums are id, title, content,url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Features in dataset, that will be neccessary to do investigation into the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main features would be \n",
    "ID\n",
    "Title\n",
    "Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file=\"stopwords.txt\"\n",
    "stopwords=[]\n",
    "if stopwords_file is not None:\n",
    "    sreader = codecs.open(\"stopwords.txt\", 'r', 'utf8')\n",
    "    for line in sreader.readlines():\n",
    "        stopwords.append(line.replace('\\n', ''))\n",
    "stoplist = set(stopwords)\n",
    "sentences = [[word for word in content.split(u' ') if word not in stoplist] for content in data]\n",
    "\n",
    "dictionary=corpora.Dictionary(sentences)\n",
    "dictionary.save(\"dictionary.dict\")\n",
    "corpus=[dictionary.doc2bow(sentence) for sentence in sentences]\n",
    "corpora.MmCorpus.serialize(\"corpus.mm\",corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A next step is to create a Bag of Words on the dataset. A dictionary would be created from all the processed documents. A dictionary will contain the number of times word appeared in the training set.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps are invloved in data preprocessing.\n",
    "\n",
    "Tokenization: in this step, we split all content of document into sentences and that into words.\n",
    "all the stop words are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the data collected from the dataset, we will be preprocessing it and make, it more clean. since there are several documents, in each document, we need to tokenize it into sentences and words, also removing all the stop words. once the data is cleaned we will make a dictionary. and then finally a corpus. A corpus is the collection of the input document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=100)\n",
    "model.save(\"model.lda\")\n",
    "model = models.ldamodel.LdaModel.load(\"model.lda\")\n",
    "word_occurs=False\n",
    "high_frequency_words=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is LDA Algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA or Latent Dirichlet Allocation is another topic model, and it does the classification of several douments according to their niche. LDA builds a document model, and model of words in each topic. All of this is modeled as the Direchlet Distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_occurs:\n",
    "    for i in range(model.num_topics):\n",
    "        print('Title ', i+1, ': ', model.print_topic(i, topn=high_frequency_words))\n",
    "else:\n",
    "    for i in range(model.num_topics):\n",
    "        hfwords = [a[0] for a in model.show_topic(i, topn=high_frequency_words)]\n",
    "        collection = 'Title' + str(i+1) + ':'\n",
    "        for word in hfwords:\n",
    "            collection += ' ' + word\n",
    "        print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('dictionary.dict')\n",
    "corpus = corpora.MmCorpus(\"corpus.mm\")\n",
    "lda = models.LdaModel.load(\"model.lda\")\n",
    "\n",
    "index = similarities.MatrixSimilarity(lda[corpus])\n",
    "index.save(\"simIndex.index\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does Similarity class work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main class is similarity, which is used to build the index of the collection of documents. once the index is build,we can check how similar is the query document to the all the vectors of numbers. \n",
    "\n",
    "Simailarity Class divides the index into several small sub indices. with the use of other functionalities, such as MatrixSimilary we can find the similarity between the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim doc2bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have used the library Gensim Doc2bow, generally it creates a dectionary and it gives the number of words appeared. and it is saved in the query_bow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to test a Model on Query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docname = \"Query.txt\"\n",
    "doc = open(docname, 'r').read()\n",
    "query_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lda = lda[query_bow]\n",
    "\n",
    "sims = index[vec_lda]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(\"Document ID\" + \" Similarity-Score\")\n",
    "for i in range(10):\n",
    "    print(\"Document ID : \" + str(sims[i][0])+\"\\n\"+\"content : \"+data[i]+\"\\n\"+\"content_similarity : \"+str(sims[i][1]))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, the results are ways much better and quite accuarate. Such code can be used to build the recommendation system, like with the help of such data, we can recommend people about blogs and artiicles according their context they like to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
